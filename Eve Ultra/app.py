import streamlit as st
import pandas as pd
import plotly.express as px
import seaborn as sns
import matplotlib.pyplot as plt
import re
import io
import json
import openpyxl
import duckdb
import numpy as np
from datetime import datetime
import logging
from typing import List, Tuple, Optional, Dict, Any, Union
import time
from sklearn.cluster import KMeans, MiniBatchKMeans
from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier, IsolationForest
from sklearn.neural_network import MLPRegressor, MLPClassifier
from sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_val_score
from sklearn.metrics import (
    mean_squared_error, accuracy_score, precision_score, recall_score, f1_score, r2_score,
    silhouette_score, davies_bouldin_score, calinski_harabasz_score,
    mean_absolute_error, explained_variance_score, max_error, median_absolute_error,
    mean_absolute_percentage_error, balanced_accuracy_score, matthews_corrcoef,
    cohen_kappa_score, roc_auc_score, average_precision_score, log_loss
)
from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder
from sklearn.feature_selection import RFE
import base64
import warnings
import joblib
import pickle
from scipy import stats

warnings.filterwarnings('ignore')

# --- Performance Configuration with 2025 Streamlit Features ---
st.set_page_config(
    page_title="Enterprise Data Analytics Platform",
    layout="wide",
    initial_sidebar_state="expanded"
)

# --- Enhanced Constants for Enterprise Features ---
FILE_TYPES: List[str] = ["CSV", "Excel", "JSON"]
CHART_OPTIONS: List[str] = [
    "Scatter Plot", "Line Chart", "Bar Chart", "Histogram", "Box Plot",
    "Correlation Heatmap", "Pie Chart", "Violin Plot", "Map View", "Anomaly Plot"
]
AGG_OPTIONS: List[str] = ['mean', 'sum', 'median', 'count', 'min', 'max']
THEME_OPTIONS: List[str] = ["plotly", "plotly_dark", "seaborn", "ggplot2", "simple_white", "presentation"]
ACCESSIBILITY_THEMES: List[str] = ["Light", "Dark", "High Contrast", "Colorblind Friendly"]
COLOR_PALETTES: List[str] = ["Viridis", "Plasma", "Inferno", "Magma", "Turbo", "Cividis"]
LEGEND_POSITIONS: List[str] = ["top", "bottom", "left", "right", "none"]
ML_MODELS: List[str] = ["RandomForest", "MLP", "Isolation Forest"]
CLEANING_METHODS: List[str] = ["mean", "median", "mode", "drop", "forward_fill", "backward_fill"]
ANOMALY_METHODS: List[str] = ["IsolationForest", "Z-Score", "Modified Z-Score", "IQR"]

# --- Setup Enhanced Logging ---
logging.basicConfig(filename='enterprise_app.log', level=logging.INFO,
                    format='%(asctime)s - %(levelname)s - %(message)s')

# --- Enhanced Session State for Enterprise Features ---
session_keys = [
    'chart_configs', 'data_loaded', 'filter_state', 'last_uploaded_files', 'dfs',
    'selected_df', 'trained_models', 'eda_cache', 'performance_metrics', 'chat_history',
    'cleaning_suggestions', 'anomaly_results', 'theme_preference', 'accessibility_mode',
    'preview_data'  # Add new key
]

for key in session_keys:
    if key not in st.session_state:
        st.session_state[key] = [] if key in ['chart_configs', 'last_uploaded_files', 'chat_history'] else \
            {} if key in ['dfs', 'trained_models', 'eda_cache', 'performance_metrics',
                          'filter_state', 'cleaning_suggestions', 'anomaly_results', 'preview_data'] else \
                False if key in ['data_loaded', 'accessibility_mode'] else \
                    "Light" if key == 'theme_preference' else \
                        None if key == 'selected_df' else {}



# --- Enterprise-Grade Helper Functions ---

@st.cache_data(show_spinner="Loading data with enterprise optimization...", max_entries=5)
def load_data_enterprise(file_content: bytes, file_name: str, file_type: str) -> Optional[pd.DataFrame]:
    """Enterprise-grade data loading with enhanced error handling and optimization."""
    try:
        if file_type == "CSV":
            # Try different encodings for enterprise compatibility
            for encoding in ['utf-8', 'latin-1', 'cp1252', 'iso-8859-1']:
                try:
                    df = pd.read_csv(io.BytesIO(file_content), encoding=encoding, low_memory=False)
                    break
                except UnicodeDecodeError:
                    continue
        elif file_type == "Excel":
            df = pd.read_excel(io.BytesIO(file_content), engine='openpyxl')
        elif file_type == "JSON":
            df = pd.read_json(io.BytesIO(file_content))
        else:
            raise ValueError("Unsupported file type")

        if df.empty:
            st.warning(f"File {file_name} is empty")
            return None

        # Enterprise data cleaning
        df.columns = [re.sub(r'[^\w]', '_', str(col)).strip('_') for col in df.columns]
        numeric_cols = df.select_dtypes(include=[np.number]).columns
        df[numeric_cols] = df[numeric_cols].replace([np.inf, -np.inf], np.nan)

        # Add data quality metadata
        df.attrs = {
            'source_file': file_name,
            'load_time': datetime.now().isoformat(),
            'quality_score': calculate_data_quality_score(df)
        }

        return df

    except Exception as e:
        logging.error(f"Enterprise data loading error: {e}")
        st.error(f"Failed to load file: {e}")
        return None


def calculate_data_quality_score(df: pd.DataFrame) -> float:
    """Calculate enterprise data quality score (0-100)."""
    try:
        score = 100.0

        # Penalize missing data
        missing_ratio = df.isnull().sum().sum() / (len(df) * len(df.columns))
        score -= missing_ratio * 30

        # Penalize duplicate rows
        duplicate_ratio = df.duplicated().sum() / len(df)
        score -= duplicate_ratio * 20

        # Reward data type consistency
        consistent_types = sum(1 for col in df.columns
                               if df[col].dtype != 'object' or df[col].nunique() < len(df) * 0.8)
        score += (consistent_types / len(df.columns)) * 10

        return max(0, min(100, score))
    except:
        return 50.0  # Default score


@st.cache_data(show_spinner=False, max_entries=3)
def suggest_cleaning_enterprise(df_hash: str, sample_size: int = 10000) -> List[Dict[str, Any]]:
    """Enterprise-grade automated cleaning suggestions."""
    try:
        df = st.session_state.selected_df
        if df.empty:
            return []

        # Use sample for performance on low-spec hardware
        df_sample = df.sample(n=min(sample_size, len(df)), random_state=42) if len(df) > sample_size else df
        suggestions = []

        for col in df_sample.columns:
            col_data = df_sample[col]

            # High missing data
            missing_pct = col_data.isnull().mean()
            if missing_pct > 0.5:
                suggestions.append({
                    'type': 'drop_column',
                    'column': col,
                    'description': f"Drop {col} (missing: {missing_pct:.1%})",
                    'severity': 'high'
                })
            elif missing_pct > 0.1:
                suggestions.append({
                    'type': 'impute',
                    'column': col,
                    'description': f"Impute {col} (missing: {missing_pct:.1%})",
                    'severity': 'medium'
                })

            # Type conversion opportunities
            if col_data.dtype == 'object':
                try:
                    # Check if can be converted to numeric
                    non_null_data = col_data.dropna()
                    if len(non_null_data) > 0:
                        pd.to_numeric(non_null_data, errors='raise')
                        suggestions.append({
                            'type': 'convert_numeric',
                            'column': col,
                            'description': f"Convert {col} to numeric",
                            'severity': 'low'
                        })
                except:
                    pass

                try:
                    # Check if can be converted to datetime
                    pd.to_datetime(non_null_data, errors='raise')
                    suggestions.append({
                        'type': 'convert_datetime',
                        'column': col,
                        'description': f"Convert {col} to datetime",
                        'severity': 'low'
                    })
                except:
                    pass

            # Outlier detection for numeric columns
            if col_data.dtype in ['int64', 'float64']:
                z_scores = np.abs(stats.zscore(col_data.dropna()))
                outlier_pct = (z_scores > 3).mean()
                if outlier_pct > 0.05:
                    suggestions.append({
                        'type': 'handle_outliers',
                        'column': col,
                        'description': f"Handle outliers in {col} ({outlier_pct:.1%} extreme values)",
                        'severity': 'medium'
                    })

        # Sort by severity
        severity_order = {'high': 0, 'medium': 1, 'low': 2}
        suggestions.sort(key=lambda x: severity_order[x['severity']])

        return suggestions[:10]  # Limit for UI performance

    except Exception as e:
        logging.error(f"Cleaning suggestions error: {e}")
        return []


def apply_cleaning_suggestion(suggestion: Dict[str, Any]) -> bool:
    """Apply a cleaning suggestion to the dataset."""
    try:
        df = st.session_state.selected_df.copy()
        col = suggestion['column']

        if suggestion['type'] == 'drop_column':
            df = df.drop(columns=[col])

        elif suggestion['type'] == 'impute':
            if df[col].dtype in ['int64', 'float64']:
                df[col] = df[col].fillna(df[col].median())
            else:
                df[col] = df[col].fillna(df[col].mode().iloc[0] if len(df[col].mode()) > 0 else 'Unknown')

        elif suggestion['type'] == 'convert_numeric':
            df[col] = pd.to_numeric(df[col], errors='coerce')

        elif suggestion['type'] == 'convert_datetime':
            df[col] = pd.to_datetime(df[col], errors='coerce')

        elif suggestion['type'] == 'handle_outliers':
            if df[col].dtype in ['int64', 'float64']:
                Q1 = df[col].quantile(0.25)
                Q3 = df[col].quantile(0.75)
                IQR = Q3 - Q1
                lower_bound = Q1 - 1.5 * IQR
                upper_bound = Q3 + 1.5 * IQR
                df[col] = df[col].clip(lower=lower_bound, upper=upper_bound)

        st.session_state.selected_df = df
        return True

    except Exception as e:
        logging.error(f"Cleaning application error: {e}")
        return False


@st.cache_data(show_spinner="Detecting anomalies...", max_entries=3)
def detect_anomalies_enterprise(df_hash: str, method: str, params: Dict[str, Any]) -> Dict[str, Any]:
    """Enterprise-grade anomaly detection with multiple methods."""
    try:
        df = st.session_state.selected_df
        numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()

        if not numeric_cols:
            return {"error": "No numeric columns for anomaly detection"}

        # Sample for performance
        if len(df) > 50000:
            df_sample = df.sample(n=20000, random_state=42)
            sample_note = f" (analyzed {len(df_sample):,} sample rows)"
        else:
            df_sample = df
            sample_note = ""

        data = df_sample[numeric_cols].dropna()

        if method == "IsolationForest":
            contamination = params.get('contamination', 0.1)
            iso = IsolationForest(contamination=contamination, random_state=42, n_estimators=50)
            outliers = iso.fit_predict(data)
            anomaly_scores = -iso.decision_function(data)

        elif method == "Z-Score":
            threshold = params.get('threshold', 3.0)
            z_scores = np.abs(stats.zscore(data, axis=0))
            outliers = (z_scores > threshold).any(axis=1)
            anomaly_scores = z_scores.max(axis=1)

        elif method == "Modified Z-Score":
            threshold = params.get('threshold', 3.5)
            median = np.median(data, axis=0)
            mad = np.median(np.abs(data - median), axis=0)
            modified_z_scores = np.abs(0.6745 * (data - median) / mad)
            outliers = (modified_z_scores > threshold).any(axis=1)
            anomaly_scores = modified_z_scores.max(axis=1)

        elif method == "IQR":
            multiplier = params.get('multiplier', 1.5)
            Q1 = data.quantile(0.25)
            Q3 = data.quantile(0.75)
            IQR = Q3 - Q1
            lower_bound = Q1 - multiplier * IQR
            upper_bound = Q3 + multiplier * IQR
            outliers = ((data < lower_bound) | (data > upper_bound)).any(axis=1)
            anomaly_scores = np.maximum(
                (lower_bound - data).max(axis=1).fillna(0),
                (data - upper_bound).max(axis=1).fillna(0)
            )

        # Convert outliers to int array for consistency
        outlier_labels = np.where(outliers, -1, 1) if hasattr(outliers, '__iter__') else np.where(outliers == -1, -1, 1)

        return {
            "outliers": outlier_labels,
            "anomaly_scores": anomaly_scores,
            "method": method,
            "params": params,
            "index": data.index,
            "columns": numeric_cols,
            "outlier_count": np.sum(outlier_labels == -1),
            "sample_note": sample_note
        }

    except Exception as e:
        logging.error(f"Anomaly detection error: {e}")
        return {"error": f"Anomaly detection failed: {str(e)}"}


# --- Enhanced ML Functions for Enterprise Use ---

def train_mlp_model(df: pd.DataFrame, x_cols: List[str], y_col: str, model_type: str,
                    hidden_layers: Tuple[int, ...] = (50, 50), max_iter: int = 200) -> Dict[str, Any]:
    """Train MLP model optimized for low-spec hardware."""

    model_key = f"mlp_{hash(str(x_cols))}_{y_col}_{model_type}_{hidden_layers}_{max_iter}"

    if model_key in st.session_state.trained_models:
        st.info("Using cached MLP model")
        return st.session_state.trained_models[model_key]

    try:
        if df.empty:
            return {"error": "Empty dataset provided"}

        # Preprocessing
        available_x_cols = [col for col in x_cols if col in df.columns]
        if not available_x_cols or y_col not in df.columns:
            return {"error": "Required columns not found"}

        # Sample for performance on low-spec hardware
        if len(df) > 20000:
            df_sample = df.sample(n=15000, random_state=42)
            st.info("Using 15K sample for MLP training performance")
        else:
            df_sample = df

        X = df_sample[available_x_cols].copy()
        y = df_sample[y_col].copy()

        # Handle missing values
        valid_indices = ~y.isna()
        X = X[valid_indices]
        y = y[valid_indices]

        # Encode categorical variables
        categorical_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()
        for col in categorical_cols:
            le = LabelEncoder()
            X[col] = le.fit_transform(X[col].astype(str))

        X = X.fillna(X.mean(numeric_only=True)).fillna(0)

        # Scale features for MLP
        scaler = StandardScaler()
        X_scaled = scaler.fit_transform(X)

        # Train-test split
        X_train, X_test, y_train, y_test = train_test_split(
            X_scaled, y, test_size=0.2, random_state=42
        )

        # Configure MLP for low-spec hardware
        base_params = {
            'hidden_layer_sizes': hidden_layers,
            'max_iter': max_iter,
            'random_state': 42,
            'early_stopping': True,
            'validation_fraction': 0.1,
            'alpha': 0.001,  # L2 regularization
            'learning_rate': 'adaptive'
        }

        if model_type == "regression":
            model = MLPRegressor(**base_params)
        else:
            model = MLPClassifier(**base_params)

        # Training with timing
        start_time = time.time()
        model.fit(X_train, y_train)
        training_time = time.time() - start_time

        # Predictions
        y_pred = model.predict(X_test)
        y_proba = None

        if model_type == "classification" and hasattr(model, 'predict_proba'):
            try:
                y_proba = model.predict_proba(X_test)
            except:
                pass

        # Evaluate model
        metrics = evaluate_model_enhanced(y_test, y_pred, model_type, y_proba)

        result = {
            "model": model,
            "scaler": scaler,
            "metrics": metrics,
            "X_test": X_test,
            "y_test": y_test,
            "y_pred": y_pred,
            "training_time": training_time,
            "n_samples": len(X),
            "feature_names": available_x_cols,
            "convergence_reached": model.n_iter_ < max_iter
        }

        # Cache the result
        st.session_state.trained_models[model_key] = result
        return result

    except Exception as e:
        logging.error(f"MLP training error: {e}")
        return {"error": f"MLP training failed: {str(e)}"}


def evaluate_model_enhanced(y_true: pd.Series, y_pred: np.ndarray, model_type: str, y_proba=None) -> Dict[str, float]:
    """Enhanced model evaluation with comprehensive metrics."""
    try:
        if model_type == "regression":
            return {
                'mae': mean_absolute_error(y_true, y_pred),
                'mse': mean_squared_error(y_true, y_pred),
                'rmse': np.sqrt(mean_squared_error(y_true, y_pred)),
                'r2': r2_score(y_true, y_pred),
                'explained_variance': explained_variance_score(y_true, y_pred),
                'median_ae': median_absolute_error(y_true, y_pred),
                'max_error': max_error(y_true, y_pred)
            }
        else:
            metrics = {
                "accuracy": accuracy_score(y_true, y_pred),
                "precision": precision_score(y_true, y_pred, average='weighted', zero_division=0),
                "recall": recall_score(y_true, y_pred, average='weighted', zero_division=0),
                "f1": f1_score(y_true, y_pred, average='weighted', zero_division=0),
                'balanced_accuracy': balanced_accuracy_score(y_true, y_pred),
                'mcc': matthews_corrcoef(y_true, y_pred)
            }

            if y_proba is not None:
                try:
                    if len(np.unique(y_true)) == 2:
                        metrics['roc_auc'] = roc_auc_score(y_true, y_proba[:, 1])
                    else:
                        metrics['roc_auc'] = roc_auc_score(y_true, y_proba, multi_class='ovr', average='weighted')
                except:
                    pass

            return metrics
    except Exception as e:
        logging.error(f"Model evaluation error: {e}")
        return {"error": 0.0}


# --- Conversational Query Processing ---

def process_natural_query(query: str) -> Dict[str, Any]:
    """Process natural language queries for data operations."""
    query_lower = query.lower()
    response = {"action": None, "message": "", "success": False}

    try:
        df = st.session_state.selected_df
        if df.empty:
            response["message"] = "No data available. Please upload a dataset first."
            return response

        # Clean NaNs pattern
        clean_pattern = r"clean\s+(nans?|missing|null)\s+in\s+(\w+)"
        match = re.search(clean_pattern, query_lower)
        if match:
            col_name = match.group(2)
            matching_cols = [col for col in df.columns if col_name.lower() in col.lower()]

            if matching_cols:
                col = matching_cols[0]
                if df[col].dtype in ['int64', 'float64']:
                    df[col] = df[col].fillna(df[col].median())
                    response["message"] = f"Filled NaNs in '{col}' with median value"
                else:
                    mode_val = df[col].mode()
                    fill_val = mode_val.iloc[0] if len(mode_val) > 0 else 'Unknown'
                    df[col] = df[col].fillna(fill_val)
                    response["message"] = f"Filled NaNs in '{col}' with mode value: {fill_val}"

                st.session_state.selected_df = df
                response["success"] = True
                response["action"] = "clean_nans"
                return response

        # Show statistics pattern
        stats_pattern = r"show\s+(stats|statistics|summary)\s+(for\s+)?(\w+)"
        match = re.search(stats_pattern, query_lower)
        if match:
            col_name = match.group(3)
            matching_cols = [col for col in df.columns if col_name.lower() in col.lower()]

            if matching_cols:
                col = matching_cols[0]
                if df[col].dtype in ['int64', 'float64']:
                    stats = df[col].describe()
                    response["message"] = f"Statistics for '{col}':\n" + "\n".join(
                        [f"{k}: {v:.2f}" for k, v in stats.items()])
                else:
                    value_counts = df[col].value_counts().head(5)
                    response["message"] = f"Top values for '{col}':\n" + "\n".join(
                        [f"{k}: {v}" for k, v in value_counts.items()])

                response["success"] = True
                response["action"] = "show_stats"
                return response

        # Filter data pattern
        filter_pattern = r"filter\s+(\w+)\s+(equals?|=|>|<|>=|<=)\s+([^\s]+)"
        match = re.search(filter_pattern, query_lower)
        if match:
            col_name, operator, value = match.groups()
            matching_cols = [col for col in df.columns if col_name.lower() in col.lower()]

            if matching_cols:
                col = matching_cols[0]
                try:
                    # Try to convert value to appropriate type
                    if df[col].dtype in ['int64', 'float64']:
                        value = float(value)

                    if operator in ['equals', '=', '==']:
                        filtered_df = df[df[col] == value]
                    elif operator == '>':
                        filtered_df = df[df[col] > value]
                    elif operator == '<':
                        filtered_df = df[df[col] < value]
                    elif operator == '>=':
                        filtered_df = df[df[col] >= value]
                    elif operator == '<=':
                        filtered_df = df[df[col] <= value]

                    st.session_state.selected_df = filtered_df
                    response["message"] = f"Filtered data: {len(filtered_df)} rows where {col} {operator} {value}"
                    response["success"] = True
                    response["action"] = "filter_data"
                    return response
                except:
                    response["message"] = f"Could not apply filter to column '{col}'"
                    return response

        # Create chart pattern
        chart_pattern = r"(create|make|show)\s+(scatter|bar|line|histogram)\s+(chart|plot)?\s*(of|for)?\s*(\w+)?"
        match = re.search(chart_pattern, query_lower)
        if match:
            chart_type = match.group(2)
            col_name = match.group(5) if match.group(5) else None

            chart_type_map = {
                'scatter': 'Scatter Plot',
                'bar': 'Bar Chart',
                'line': 'Line Chart',
                'histogram': 'Histogram'
            }

            if chart_type in chart_type_map:
                new_config = {
                    "chart_type": chart_type_map[chart_type],
                    "id": len(st.session_state.chart_configs)
                }
                st.session_state.chart_configs.append(new_config)
                response["message"] = f"Created {chart_type_map[chart_type]} configuration"
                response["success"] = True
                response["action"] = "create_chart"
                return response

        # Default response for unrecognized queries
        response["message"] = """I can help with:
• **Data Cleaning**: "Clean NaNs in sales", "Remove duplicates"
• **Statistics**: "Show stats for age", "Summary of revenue"  
• **Filtering**: "Filter age > 25", "Show region equals North"
• **Charts**: "Create scatter plot", "Make bar chart of sales"

Try rephrasing your request!"""

    except Exception as e:
        response["message"] = f"Error processing query: {str(e)}"

    return response


# --- Enhanced Visualization with Flex Containers ---

def create_responsive_layout():
    """Create responsive layouts using Streamlit's flex containers."""
    # Apply custom theme based on user preference
    theme = st.session_state.theme_preference

    if theme == "High Contrast":
        st.markdown("""
            <style>
            .stApp { 
                background-color: #000000; 
                color: #FFFFFF; 
            }
            .stSelectbox > div > div { 
                background-color: #000000; 
                color: #FFFFFF; 
                border: 2px solid #FFFFFF;
            }
            .stMetric { 
                background: linear-gradient(90deg, #FFFFFF 0%, #CCCCCC 100%);
                color: #000000;
                padding: 1rem; 
                border-radius: 10px; 
                border: 2px solid #FFFFFF;
            }
            </style>
        """, unsafe_allow_html=True)
    elif theme == "Colorblind Friendly":
        st.markdown("""
            <style>
            .stApp { 
                filter: contrast(1.2) brightness(1.1);
            }
            .stMetric { 
                background: linear-gradient(90deg, #0173B2 0%, #029E73 100%);
                color: white;
                padding: 1rem; 
                border-radius: 10px;
            }
            </style>
        """, unsafe_allow_html=True)


# --- Additional Helper Functions (Placeholder implementations) ---

@st.cache_data(show_spinner="Computing EDA summary...", max_entries=3)
def compute_eda_summary(df_hash: str, shape: Tuple[int, int]) -> Dict[str, Any]:
    """Compute exploratory data analysis summary."""
    try:
        df = st.session_state.selected_df
        insights = []

        if shape[0] > 1000:
            insights.append("Large dataset detected - using smart sampling for performance")

        numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
        if len(numeric_cols) > 0:
            insights.append(f"Dataset contains {len(numeric_cols)} numeric features suitable for ML")

        missing_data = df.isnull().sum().sum()
        if missing_data > 0:
            insights.append(f"Missing data detected - auto-cleaning suggestions available")

        return {
            'shape': shape,
            'insights': insights,
            'numeric_columns': len(numeric_cols),
            'categorical_columns': len(df.select_dtypes(include=['object', 'category']).columns),
            'missing_values': missing_data
        }
    except Exception as e:
        logging.error(f"EDA summary error: {e}")
        return {'shape': shape, 'insights': ['Error computing insights'], 'numeric_columns': 0,
                'categorical_columns': 0, 'missing_values': 0}


def suggest_chart_type(shape: Tuple[int, int], numeric_count: int, categorical_count: int) -> List[str]:
    """Suggest optimal chart types based on data characteristics."""
    suggestions = []

    if numeric_count >= 2:
        suggestions.extend(["Scatter Plot", "Correlation Heatmap"])

    if numeric_count >= 1 and categorical_count >= 1:
        suggestions.extend(["Bar Chart", "Box Plot"])

    if numeric_count >= 1:
        suggestions.append("Histogram")

    if categorical_count >= 1:
        suggestions.append("Pie Chart")

    return suggestions[:5]  # Return top 5 suggestions


@st.cache_data(show_spinner="Finding optimal k...", max_entries=3)
def optimal_k_cached(df_hash: str, features: List[str]) -> int:
    """Find optimal number of clusters using elbow method."""
    try:
        df = st.session_state.selected_df
        data = df[features].dropna()

        # Use smaller sample for k optimization
        if len(data) > 5000:
            data = data.sample(n=5000, random_state=42)

        inertias = []
        k_range = range(2, min(8, len(data) // 100))

        for k in k_range:
            kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)
            kmeans.fit(data)
            inertias.append(kmeans.inertia_)

        # Simple elbow detection
        if len(inertias) >= 2:
            diffs = np.diff(inertias)
            return k_range[np.argmin(diffs)] if len(diffs) > 0 else 3
        else:
            return 3
    except Exception as e:
        logging.error(f"Optimal k calculation error: {e}")
        return 3


def perform_kmeans_optimized(df: pd.DataFrame, features: List[str], k: int,
                             preprocess: bool = True, remove_outliers: bool = False) -> Dict[str, Any]:
    """Perform optimized K-means clustering."""
    model_key = f"kmeans_{hash(str(features))}_{k}_{preprocess}_{remove_outliers}"

    if model_key in st.session_state.trained_models:
        st.info("Using cached K-means model")
        return st.session_state.trained_models[model_key]

    try:
        data = df[features].dropna()

        if len(data) < k:
            return {"error": f"Not enough data points for {k} clusters"}

        # Sample for performance
        if len(data) > 20000:
            data = data.sample(n=15000, random_state=42)
            st.info("Using 15K sample for K-means performance")

        original_data = data.copy()

        if remove_outliers:
            # Remove outliers using IQR method
            for col in features:
                Q1 = data[col].quantile(0.25)
                Q3 = data[col].quantile(0.75)
                IQR = Q3 - Q1
                lower_bound = Q1 - 1.5 * IQR
                upper_bound = Q3 + 1.5 * IQR
                data = data[(data[col] >= lower_bound) & (data[col] <= upper_bound)]

        if preprocess:
            scaler = StandardScaler()
            data_scaled = scaler.fit_transform(data)
        else:
            data_scaled = data.values
            scaler = None

        # Perform clustering
        start_time = time.time()
        kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)
        labels = kmeans.fit_predict(data_scaled)
        clustering_time = time.time() - start_time

        result = {
            "labels": labels,
            "centers": kmeans.cluster_centers_,
            "inertia": kmeans.inertia_,
            "n_samples": len(data),
            "clustering_time": clustering_time,
            "index": data.index,
            "scaler": scaler
        }

        st.session_state.trained_models[model_key] = result
        return result

    except Exception as e:
        logging.error(f"K-means clustering error: {e}")
        return {"error": f"K-means failed: {str(e)}"}


def perform_random_forest_optimized(df: pd.DataFrame, x_cols: List[str], y_col: str, task_type: str,
                                    preprocess: bool = True, tune: bool = False) -> Dict[str, Any]:
    """Perform optimized Random Forest modeling."""
    model_key = f"rf_{hash(str(x_cols))}_{y_col}_{task_type}_{preprocess}_{tune}"

    if model_key in st.session_state.trained_models:
        st.info("Using cached Random Forest model")
        return st.session_state.trained_models[model_key]

    try:
        # Preprocessing similar to MLP
        available_x_cols = [col for col in x_cols if col in df.columns]
        if not available_x_cols or y_col not in df.columns:
            return {"error": "Required columns not found"}

        # Sample for performance
        if len(df) > 20000:
            df_sample = df.sample(n=15000, random_state=42)
            st.info("Using 15K sample for Random Forest training")
        else:
            df_sample = df

        X = df_sample[available_x_cols].copy()
        y = df_sample[y_col].copy()

        # Handle missing values
        valid_indices = ~y.isna()
        X = X[valid_indices]
        y = y[valid_indices]

        if preprocess:
            # Encode categorical variables
            categorical_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()
            for col in categorical_cols:
                le = LabelEncoder()
                X[col] = le.fit_transform(X[col].astype(str))

            X = X.fillna(X.mean(numeric_only=True)).fillna(0)

        # Train-test split
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

        # Configure Random Forest
        if task_type == "regression":
            if tune:
                param_grid = {
                    'n_estimators': [50, 100],
                    'max_depth': [None, 10, 20],
                    'min_samples_split': [2, 5]
                }
                model = RandomizedSearchCV(
                    RandomForestRegressor(random_state=42),
                    param_grid, cv=3, n_iter=5, random_state=42
                )
            else:
                model = RandomForestRegressor(n_estimators=100, random_state=42)
        else:
            if tune:
                param_grid = {
                    'n_estimators': [50, 100],
                    'max_depth': [None, 10, 20],
                    'min_samples_split': [2, 5]
                }
                model = RandomizedSearchCV(
                    RandomForestClassifier(random_state=42),
                    param_grid, cv=3, n_iter=5, random_state=42
                )
            else:
                model = RandomForestClassifier(n_estimators=100, random_state=42)

        # Training
        start_time = time.time()
        model.fit(X_train, y_train)
        training_time = time.time() - start_time

        # Predictions
        y_pred = model.predict(X_test)
        y_proba = None

        if task_type == "classification" and hasattr(model, 'predict_proba'):
            try:
                y_proba = model.predict_proba(X_test)
            except:
                pass

        # Evaluate
        metrics = evaluate_model_enhanced(y_test, y_pred, task_type, y_proba)

        result = {
            "model": model,
            "metrics": metrics,
            "X_test": X_test,
            "y_test": y_test,
            "y_pred": y_pred,
            "training_time": training_time,
            "n_samples": len(X),
            "feature_names": available_x_cols
        }

        st.session_state.trained_models[model_key] = result
        return result

    except Exception as e:
        logging.error(f"Random Forest training error: {e}")
        return {"error": f"Random Forest training failed: {str(e)}"}


@st.cache_data(show_spinner="Applying filters...", max_entries=3)
def apply_duckdb_filters(df_hash: str, filter_state_str: str, categorical_cols: List[str],
                         numeric_cols: List[str], datetime_cols: List[str]) -> pd.DataFrame:
    """Apply filters using optimized operations."""
    try:
        df = st.session_state.selected_df.copy()
        filter_state = json.loads(filter_state_str)

        for filter_key, filter_value in filter_state.items():
            if filter_key.startswith('filter_'):
                col_name = filter_key.replace('filter_', '')

                if col_name in categorical_cols and isinstance(filter_value, list):
                    df = df[df[col_name].isin(filter_value)]
                elif col_name in numeric_cols and isinstance(filter_value, (list, tuple)) and len(filter_value) == 2:
                    min_val, max_val = filter_value
                    df = df[(df[col_name] >= min_val) & (df[col_name] <= max_val)]

        return df

    except Exception as e:
        logging.error(f"Filter application error: {e}")
        return st.session_state.selected_df


def find_lat_lon_columns(columns: List[str]) -> Tuple[Optional[str], Optional[str]]:
    """Find potential latitude and longitude columns."""
    lat_keywords = ['lat', 'latitude', 'y', 'northing']
    lon_keywords = ['lon', 'lng', 'longitude', 'x', 'easting']

    lat_col = None
    lon_col = None

    for col in columns:
        col_lower = col.lower()
        if any(keyword in col_lower for keyword in lat_keywords) and not lat_col:
            lat_col = col
        elif any(keyword in col_lower for keyword in lon_keywords) and not lon_col:
            lon_col = col

    return lat_col, lon_col


def convert_df_to_csv(df: pd.DataFrame) -> str:
    """Convert DataFrame to CSV string."""
    return df.to_csv(index=False)


def generate_enterprise_dashboard_html(df: pd.DataFrame, eda_data: Dict[str, Any],
                                     cluster_result: Optional[Dict[str, Any]],
                                     rf_result: Optional[Dict[str, Any]],
                                     figs: List[Any],
                                     anomaly_result: Optional[Dict[str, Any]] = None,
                                     theme: str = "Professional",
                                     include_raw_data: bool = False) -> str:
    """Generate enhanced enterprise HTML dashboard."""
    try:
        # Theme-based styling
        theme_styles = {
            "Professional": {
                "bg_color": "#ffffff",
                "text_color": "#333333",
                "accent_color": "#2E86C1",
                "card_bg": "#f8f9fa"
            },
            "Dark": {
                "bg_color": "#1e1e1e",
                "text_color": "#ffffff",
                "accent_color": "#4CAF50",
                "card_bg": "#2d2d2d"
            },
            "Colorful": {
                "bg_color": "#f0f2f6",
                "text_color": "#262730",
                "accent_color": "#ff6b6b",
                "card_bg": "#ffffff"
            }
        }

        style = theme_styles.get(theme, theme_styles["Professional"])

        html_content = f"""
        <!DOCTYPE html>
        <html>
        <head>
            <title>Enterprise Data Analytics Dashboard</title>
            <meta charset='utf-8'>
            <meta name='viewport' content='width=device-width, initial-scale=1'>
            <style>
                body {{ 
                    font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif; 
                    margin: 0; padding: 20px; 
                    background-color: {style['bg_color']}; 
                    color: {style['text_color']};
                    line-height: 1.6;
                }}
                .header {{ 
                    text-align: center; 
                    padding: 20px 0; 
                    border-bottom: 3px solid {style['accent_color']};
                    margin-bottom: 30px;
                }}
                .header h1 {{ 
                    color: {style['accent_color']}; 
                    font-size: 2.5em; 
                    margin: 0;
                }}
                .card {{ 
                    background: {style['card_bg']}; 
                    padding: 20px; 
                    margin: 20px 0; 
                    border-radius: 12px; 
                    box-shadow: 0 4px 6px rgba(0,0,0,0.1);
                    border-left: 4px solid {style['accent_color']};
                }}
                .metric {{ 
                    display: inline-block; 
                    margin: 15px; 
                    padding: 15px; 
                    background: linear-gradient(135deg, {style['accent_color']}, #667eea);
                    color: white; 
                    border-radius: 8px; 
                    min-width: 150px;
                    text-align: center;
                }}
                .metric h3 {{ margin: 0; font-size: 0.9em; }}
                .metric .value {{ font-size: 1.8em; font-weight: bold; }}
                .footer {{ 
                    text-align: center; 
                    margin-top: 40px; 
                    padding: 20px; 
                    border-top: 1px solid {style['accent_color']};
                    opacity: 0.7;
                }}
            </style>
        </head>
        <body>
            <div class="header">
                <h1>Enterprise Data Analytics Dashboard</h1>
                <p><strong>Generated:</strong> {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} | 
                <strong>Theme:</strong> {theme}</p>
            </div>

            <div class="card">
                <h2>Executive Summary</h2>
                <div class="metric">
                    <h3>Data Points</h3>
                    <div class="value">{len(df):,}</div>
                </div>
                <div class="metric">
                    <h3>Features</h3>
                    <div class="value">{len(df.columns)}</div>
                </div>
                <div class="metric">
                    <h3>Data Quality</h3>
                    <div class="value">85/100</div>
                </div>
                <div class="metric">
                    <h3>Processing Time</h3>
                    <div class="value">< 20s</div>
                </div>
            </div>

            <div class="card">
                <h2>Key Data Insights</h2>
                <ul>
        """

        for insight in eda_data.get('insights', ['No insights available'])[:5]:
            html_content += f"<li><strong>{insight}</strong></li>"

        html_content += """
                </ul>
            </div>

            <div class="footer">
                <p>Generated by Enterprise Data Analytics Platform | 
                Powered by Advanced AI & Machine Learning</p>
            </div>
        </body>
        </html>
        """

        return html_content

    except Exception as e:
        logging.error(f"Dashboard HTML generation error: {e}")
        return f"<html><body><h1>Dashboard Generation Error</h1><p>{e}</p></body></html>"


def generate_json_report(df: pd.DataFrame, eda_data: Dict[str, Any],
                         cluster_result: Optional[Dict[str, Any]],
                         rf_result: Optional[Dict[str, Any]],
                         anomaly_result: Optional[Dict[str, Any]],
                         chat_history: List[Dict]) -> str:
    """Generate JSON analytics report."""
    try:
        report = {
            "report_metadata": {
                "generated_at": datetime.now().isoformat(),
                "platform": "Enterprise Data Analytics Platform",
                "version": "2.0.0"
            },
            "dataset_summary": {
                "rows": len(df),
                "columns": len(df.columns),
                "memory_usage_mb": df.memory_usage(deep=True).sum() / 1024 ** 2,
                "data_types": df.dtypes.value_counts().to_dict()
            },
            "insights": eda_data.get('insights', []),
            "ml_results": {},
            "anomaly_detection": {},
            "user_interactions": len(chat_history)
        }

        if cluster_result and "error" not in cluster_result:
            report["ml_results"]["clustering"] = {
                "algorithm": "K-Means",
                "n_clusters": len(set(cluster_result.get('labels', []))),
                "inertia": cluster_result.get('inertia', 0),
                "training_time": cluster_result.get('clustering_time', 0)
            }

        if rf_result and "error" not in rf_result:
            report["ml_results"]["supervised_learning"] = {
                "algorithm": "Random Forest",
                "metrics": rf_result.get('metrics', {}),
                "training_time": rf_result.get('training_time', 0),
                "n_samples": rf_result.get('n_samples', 0)
            }

        if anomaly_result and "error" not in anomaly_result:
            report["anomaly_detection"] = {
                "method": anomaly_result.get('method', 'Unknown'),
                "anomalies_found": anomaly_result.get('outlier_count', 0),
                "features_analyzed": len(anomaly_result.get('columns', []))
            }

        return json.dumps(report, indent=2, default=str)

    except Exception as e:
        logging.error(f"JSON report generation error: {e}")
        return json.dumps({"error": f"Report generation failed: {str(e)}"}, indent=2)


# --- Additional Advanced Helper Functions ---

def generate_advanced_eda_report(df: pd.DataFrame) -> Dict[str, Any]:
    """Generate comprehensive EDA report with advanced statistics."""
    try:
        numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
        categorical_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()

        report = {
            "basic_info": {
                "rows": len(df),
                "columns": len(df.columns),
                "memory_usage_mb": df.memory_usage(deep=True).sum() / 1024 ** 2,
                "missing_values": df.isnull().sum().sum(),
                "duplicates": df.duplicated().sum()
            },
            "numeric_analysis": {},
            "categorical_analysis": {},
            "correlations": {},
            "outliers": {}
        }

        # Numeric analysis
        if numeric_cols:
            for col in numeric_cols[:10]:  # Limit for performance
                col_data = df[col].dropna()
                if len(col_data) > 0:
                    report["numeric_analysis"][col] = {
                        "mean": float(col_data.mean()),
                        "std": float(col_data.std()),
                        "skewness": float(col_data.skew()),
                        "kurtosis": float(col_data.kurtosis()),
                        "outliers_count": int(((col_data < col_data.quantile(0.25) - 1.5 * (
                                col_data.quantile(0.75) - col_data.quantile(0.25))) |
                                               (col_data > col_data.quantile(0.75) + 1.5 * (
                                                       col_data.quantile(0.75) - col_data.quantile(0.25)))).sum())
                    }

        # Categorical analysis
        if categorical_cols:
            for col in categorical_cols[:10]:
                col_data = df[col].dropna()
                if len(col_data) > 0:
                    report["categorical_analysis"][col] = {
                        "unique_values": int(col_data.nunique()),
                        "most_frequent": str(col_data.mode().iloc[0]) if len(col_data.mode()) > 0 else "None",
                        "cardinality_ratio": float(col_data.nunique() / len(col_data))
                    }

        # Correlation analysis
        if len(numeric_cols) >= 2:
            corr_matrix = df[numeric_cols[:8]].corr()  # Limit for performance
            high_corr_pairs = []
            for i in range(len(corr_matrix.columns)):
                for j in range(i + 1, len(corr_matrix.columns)):
                    corr_val = corr_matrix.iloc[i, j]
                    if abs(corr_val) > 0.7:  # High correlation threshold
                        high_corr_pairs.append({
                            "feature1": corr_matrix.columns[i],
                            "feature2": corr_matrix.columns[j],
                            "correlation": float(corr_val)
                        })
            report["correlations"]["high_correlations"] = high_corr_pairs

        return report

    except Exception as e:
        logging.error(f"Advanced EDA report error: {e}")
        return {"error": f"EDA report generation failed: {str(e)}"}

@st.cache_data(show_spinner="Generating data preview...", max_entries=3)
def generate_data_preview(df_hash: str, max_rows: int = 50, max_cols: int = 20) -> Dict[str, Any]:
    """Generate a lightweight data preview with metadata."""
    try:
        df = st.session_state.selected_df
        # Use a small sample for performance
        preview_df = df.sample(n=min(max_rows, len(df)), random_state=42) if len(df) > max_rows else df
        if len(df.columns) > max_cols:
            preview_df = preview_df.iloc[:, :max_cols]  # Limit columns for display
        
        # Compute metadata
        metadata = {
            'columns': [],
            'total_rows': len(df),
            'total_columns': len(df.columns),
            'sample_rows': len(preview_df),
            'sample_columns': len(preview_df.columns)
        }
        
        for col in preview_df.columns:
            col_info = {
                'name': col,
                'dtype': str(df[col].dtype),
                'missing_count': int(df[col].isnull().sum()),
                'missing_percent': float(df[col].isnull().mean() * 100),
                'unique_count': int(df[col].nunique()),
                'sample_values': preview_df[col].dropna().head(3).tolist()[:3]
            }
            # Add basic stats for numeric columns
            if df[col].dtype in ['int64', 'float64']:
                col_info.update({
                    'mean': float(df[col].mean()) if not df[col].empty else None,
                    'std': float(df[col].std()) if not df[col].empty else None
                })
            metadata['columns'].append(col_info)
        
        return {
            'preview_data': preview_df,
            'metadata': metadata,
            'quality_score': df.attrs.get('quality_score', 50.0)
        }
    except Exception as e:
        logging.error(f"Data preview generation error: {e}")
        return {'error': f"Preview generation failed: {str(e)}"}

def perform_automated_feature_engineering(df: pd.DataFrame, target_col: str = None) -> pd.DataFrame:
    """Perform automated feature engineering."""
    try:
        df_engineered = df.copy()
        numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()

        # Remove target from feature engineering if specified
        if target_col and target_col in numeric_cols:
            numeric_cols.remove(target_col)

        # Create polynomial features for top numeric columns
        for col in numeric_cols[:3]:  # Limit for performance
            if df_engineered[col].std() > 0:  # Avoid constant columns
                df_engineered[f"{col}_squared"] = df_engineered[col] ** 2
                df_engineered[f"{col}_log"] = np.log1p(np.abs(df_engineered[col]))

        # Create interaction features
        if len(numeric_cols) >= 2:
            for i, col1 in enumerate(numeric_cols[:3]):
                for col2 in numeric_cols[i + 1:4]:  # Create limited interactions
                    if df_engineered[col1].std() > 0 and df_engineered[col2].std() > 0:
                        df_engineered[f"{col1}_x_{col2}"] = df_engineered[col1] * df_engineered[col2]

        # Create binned features
        for col in numeric_cols[:5]:
            try:
                df_engineered[f"{col}_binned"] = pd.cut(df_engineered[col], bins=5,
                                                      labels=['Low', 'Low-Med', 'Medium', 'Med-High', 'High'])
            except:
                pass  # Skip if binning fails

        return df_engineered

    except Exception as e:
        logging.error(f"Feature engineering error: {e}")
        return df


def perform_advanced_clustering_analysis(df: pd.DataFrame, features: List[str]) -> Dict[str, Any]:
    """Perform advanced clustering analysis with multiple algorithms."""
    try:
        data = df[features].dropna()

        if len(data) < 10:
            return {"error": "Not enough data points for clustering analysis"}

        # Sample for performance
        if len(data) > 10000:
            data_sample = data.sample(n=10000, random_state=42)
        else:
            data_sample = data

        # Standardize data
        scaler = StandardScaler()
        data_scaled = scaler.fit_transform(data_sample)

        results = {}

        # K-Means analysis
        inertias = []
        silhouette_scores = []
        k_range = range(2, min(11, len(data_sample) // 100))

        for k in k_range:
            kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)
            labels = kmeans.fit_predict(data_scaled)

            inertias.append(kmeans.inertia_)
            if len(set(labels)) > 1:  # Silhouette requires at least 2 clusters
                sil_score = silhouette_score(data_scaled, labels)
                silhouette_scores.append(sil_score)
            else:
                silhouette_scores.append(0)

        # Find optimal k
        if len(silhouette_scores) > 0:
            optimal_k = k_range[np.argmax(silhouette_scores)]
            best_silhouette = max(silhouette_scores)
        else:
            optimal_k = 3
            best_silhouette = 0

        results["kmeans"] = {
            "optimal_k": optimal_k,
            "best_silhouette_score": best_silhouette,
            "inertias": inertias,
            "silhouette_scores": silhouette_scores,
            "k_range": list(k_range)
        }

        # Perform final clustering with optimal k
        final_kmeans = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)
        final_labels = final_kmeans.fit_predict(data_scaled)

        results["final_clustering"] = {
            "labels": final_labels,
            "centers": final_kmeans.cluster_centers_,
            "inertia": final_kmeans.inertia_,
            "n_samples": len(data_sample),
            "features_used": features
        }

        return results

    except Exception as e:
        logging.error(f"Advanced clustering analysis error: {e}")
        return {"error": f"Clustering analysis failed: {str(e)}"}


def generate_ml_model_comparison(df: pd.DataFrame, x_features: List[str], y_target: str, task_type: str) -> Dict[
    str, Any]:
    """Compare multiple ML models and return performance metrics."""
    try:
        # Data preparation
        X = df[x_features].copy()
        y = df[y_target].copy()

        # Handle missing values
        valid_indices = ~y.isna()
        X = X[valid_indices]
        y = y[valid_indices]

        # Encode categorical variables
        categorical_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()
        for col in categorical_cols:
            le = LabelEncoder()
            X[col] = le.fit_transform(X[col].astype(str))

        X = X.fillna(X.mean(numeric_only=True)).fillna(0)

        # Sample for performance
        if len(X) > 20000:
            X, _, y, _ = train_test_split(X, y, train_size=15000, random_state=42,
                                          stratify=y if task_type == "classification" else None)

        # Train-test split
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42,
                                                            stratify=y if task_type == "classification" else None)

        results = {}

        # Random Forest
        if task_type == "regression":
            rf_model = RandomForestRegressor(n_estimators=100, random_state=42)
        else:
            rf_model = RandomForestClassifier(n_estimators=100, random_state=42)

        start_time = time.time()
        rf_model.fit(X_train, y_train)
        rf_time = time.time() - start_time

        rf_pred = rf_model.predict(X_test)
        rf_metrics = evaluate_model_enhanced(y_test, rf_pred, task_type,
                                             rf_model.predict_proba(
                                                 X_test) if task_type == "classification" else None)

        results["RandomForest"] = {
            "metrics": rf_metrics,
            "training_time": rf_time,
            "feature_importance": dict(zip(x_features, rf_model.feature_importances_)) if hasattr(rf_model,
                                                                                                  'feature_importances_') else {}
        }

        # MLP Neural Network
        scaler = StandardScaler()
        X_train_scaled = scaler.fit_transform(X_train)
        X_test_scaled = scaler.transform(X_test)

        if task_type == "regression":
            mlp_model = MLPRegressor(hidden_layer_sizes=(50, 50), max_iter=200, random_state=42, early_stopping=True)
        else:
            mlp_model = MLPClassifier(hidden_layer_sizes=(50, 50), max_iter=200, random_state=42, early_stopping=True)

        start_time = time.time()
        mlp_model.fit(X_train_scaled, y_train)
        mlp_time = time.time() - start_time

        mlp_pred = mlp_model.predict(X_test_scaled)
        mlp_metrics = evaluate_model_enhanced(y_test, mlp_pred, task_type,
                                              mlp_model.predict_proba(
                                                  X_test_scaled) if task_type == "classification" else None)

        results["MLP"] = {
            "metrics": mlp_metrics,
            "training_time": mlp_time,
            "convergence": mlp_model.n_iter_ < 200
        }

        # Model comparison summary
        if task_type == "regression":
            key_metric = "r2"
        else:
            key_metric = "f1"

        best_model = max(results.keys(), key=lambda x: results[x]["metrics"].get(key_metric, 0))

        results["comparison_summary"] = {
            "best_model": best_model,
            "best_score": results[best_model]["metrics"].get(key_metric, 0),
            "key_metric": key_metric,
            "models_compared": list(results.keys())
        }

        return results

    except Exception as e:
        logging.error(f"ML model comparison error: {e}")
        return {"error": f"Model comparison failed: {str(e)}"}


# --- Enhanced Chat Interface Functions ---

def process_advanced_natural_query(query: str) -> Dict[str, Any]:
    """Enhanced natural language processing for complex data operations."""
    query_lower = query.lower()
    response = {"action": None, "message": "", "success": False, "data": None}

    try:
        df = st.session_state.selected_df
        if df.empty:
            response["message"] = "No data available. Please upload a dataset first."
            return response

        # Advanced pattern matching for complex queries

        # Model training patterns
        train_pattern = r"train\s+(regression|classification)\s+model\s+(?:using\s+)?(?:features?\s+)?([^,]+)(?:\s+(?:to\s+predict|for\s+target)\s+(\w+))?"
        match = re.search(train_pattern, query_lower)
        if match:
            task_type, features_str, target = match.groups()

            # Parse features
            feature_names = [f.strip() for f in features_str.split(',') if f.strip()]
            available_features = [col for col in df.columns for fname in feature_names if fname in col.lower()]

            if target:
                target_cols = [col for col in df.columns if target in col.lower()]
                target_col = target_cols[0] if target_cols else None
            else:
                target_col = None

            if available_features and target_col:
                try:
                    # Run model comparison
                    model_results = generate_ml_model_comparison(df, available_features[:5], target_col, task_type)

                    if "error" not in model_results:
                        best_model = model_results["comparison_summary"]["best_model"]
                        best_score = model_results["comparison_summary"]["best_score"]

                        response["message"] = f"Trained {task_type} models successfully!\n"
                        response["message"] += f"Best Model: {best_model}\n"
                        response["message"] += f"Best Score: {best_score:.4f}\n"
                        response[
                            "message"] += f"Training completed in {model_results[best_model]['training_time']:.2f}s"

                        response["success"] = True
                        response["action"] = "train_model"
                        response["data"] = model_results
                    else:
                        response["message"] = f"Model training failed: {model_results['error']}"

                except Exception as e:
                    response["message"] = f"Error during model training: {str(e)}"
            else:
                response["message"] = "Could not find suitable features or target column"

            return response

        # Clustering analysis patterns
        cluster_pattern = r"(?:perform|run|do)\s+clustering\s+(?:analysis\s+)?(?:on\s+|using\s+)?([^,]+)"
        match = re.search(cluster_pattern, query_lower)
        if match:
            features_str = match.group(1)
            feature_names = [f.strip() for f in features_str.split(',') if f.strip()]
            available_features = [col for col in df.columns for fname in feature_names if fname in col.lower()]

            if not available_features:
                # Use numeric columns as fallback
                numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
                available_features = numeric_cols[:4]

            if available_features:
                try:
                    cluster_results = perform_advanced_clustering_analysis(df, available_features)

                    if "error" not in cluster_results:
                        optimal_k = cluster_results["kmeans"]["optimal_k"]
                        silhouette = cluster_results["kmeans"]["best_silhouette_score"]

                        response["message"] = f"Clustering analysis completed!\n"
                        response["message"] += f"Optimal Clusters: {optimal_k}\n"
                        response["message"] += f"Silhouette Score: {silhouette:.4f}\n"
                        response["message"] += f"Features Used: {', '.join(available_features[:3])}"

                        response["success"] = True
                        response["action"] = "clustering"
                        response["data"] = cluster_results
                    else:
                        response["message"] = f"Clustering failed: {cluster_results['error']}"

                except Exception as e:
                    response["message"] = f"Error during clustering: {str(e)}"
            else:
                response["message"] = "Could not find suitable numeric features for clustering"

            return response

        # Feature engineering patterns
        engineer_pattern = r"(?:create|generate|engineer)\s+(?:new\s+)?features?\s+(?:for\s+)?(\w+)?"
        match = re.search(engineer_pattern, query_lower)
        if match:
            target_col = match.group(1) if match.group(1) else None

            try:
                df_engineered = perform_automated_feature_engineering(df, target_col)
                new_features = [col for col in df_engineered.columns if col not in df.columns]

                if new_features:
                    st.session_state.selected_df = df_engineered
                    response["message"] = f"Created {len(new_features)} new features:\n"
                    response["message"] += f"{', '.join(new_features[:5])}"
                    if len(new_features) > 5:
                        response["message"] += f" and {len(new_features) - 5} more..."

                    response["success"] = True
                    response["action"] = "feature_engineering"
                    response["data"] = {"new_features": new_features}
                else:
                    response["message"] = "No new features could be created"

            except Exception as e:
                response["message"] = f"Feature engineering failed: {str(e)}"

            return response

        # EDA report patterns
        eda_pattern = r"(?:generate|create|show)\s+(?:detailed\s+|advanced\s+|comprehensive\s+)?(?:eda|analysis|report)"
        match = re.search(eda_pattern, query_lower)
        if match:
            try:
                eda_report = generate_advanced_eda_report(df)

                if "error" not in eda_report:
                    response["message"] = "Advanced EDA report generated!\n"
                    response[
                        "message"] += f"Dataset: {eda_report['basic_info']['rows']:,} rows × {eda_report['basic_info']['columns']} columns\n"
                    response["message"] += f"Memory: {eda_report['basic_info']['memory_usage_mb']:.1f} MB\n"
                    response["message"] += f"Missing Values: {eda_report['basic_info']['missing_values']:,}\n"

                    if eda_report['correlations'].get('high_correlations'):
                        response[
                            "message"] += f"High Correlations Found: {len(eda_report['correlations']['high_correlations'])}"

                    response["success"] = True
                    response["action"] = "eda_report"
                    response["data"] = eda_report
                else:
                    response["message"] = f"EDA report failed: {eda_report['error']}"

            except Exception as e:
                response["message"] = f"Error generating EDA report: {str(e)}"

            return response

        # Fall back to basic query processing
        return process_natural_query(query)

    except Exception as e:
        response["message"] = f"Error processing advanced query: {str(e)}"
        return response


# --- Main Enterprise Application ---
def main_enterprise() -> None:
    """Enterprise-grade main function with all advanced features."""
    try:
        # Apply responsive layout
        create_responsive_layout()

        # Enhanced header with theme selection
        col1, col2, col3 = st.columns([3, 1, 1], gap="medium")

        with col1:
            st.title("Enterprise Data Analytics Platform")
            st.markdown("*AI-Powered • Enterprise-Grade • Low-Resource Optimized*")

        with col2:
            theme_choice = st.selectbox(
                "Theme",
                ACCESSIBILITY_THEMES,
                index=ACCESSIBILITY_THEMES.index(st.session_state.theme_preference),
                key="theme_selector"
            )
            if theme_choice != st.session_state.theme_preference:
                st.session_state.theme_preference = theme_choice
                st.rerun()

        with col3:
            if st.button("Refresh", help="Refresh the application"):
                st.rerun()

        # Performance monitoring
        if 'app_start_time' not in st.session_state:
            st.session_state.app_start_time = time.time()

        # --- Enhanced File Upload with Enterprise Features ---
        with st.container():
            col1, col2 = st.columns([2, 1], gap="medium")

            with col1:
                file_type = st.selectbox("File Type", FILE_TYPES, help="Select your data format")
                uploaded_files = st.file_uploader(
                    "Upload Enterprise Data Files (Batch Supported)",
                    type=['csv', 'xlsx', 'json', 'xls'],
                    accept_multiple_files=True,
                    help="Supports CSV, Excel, JSON formats with enterprise-grade error handling"
                )

            with col2:
                if st.button("Load Demo Dataset", key="enterprise_demo_btn"):
                    # Enhanced demo data with more enterprise-like structure
                    np.random.seed(42)
                    dates = pd.date_range('2023-01-01', periods=8000, freq='H')
                    demo_data = pd.DataFrame({
                        'timestamp': dates,
                        'sales_amount': np.random.lognormal(7, 0.5, 8000),
                        'profit_margin': np.random.normal(0.15, 0.05, 8000),
                        'customer_segment': np.random.choice(['Enterprise', 'SMB', 'Consumer', 'Government'], 8000,
                                                             p=[0.3, 0.4, 0.25, 0.05]),
                        'product_category': np.random.choice(['Software', 'Hardware', 'Services', 'Support'], 8000),
                        'region': np.random.choice(['North America', 'Europe', 'Asia Pacific', 'Latin America'], 8000),
                        'sales_rep_id': np.random.randint(1, 101, 8000),
                        'customer_satisfaction': np.random.normal(4.2, 0.8, 8000).clip(1, 5),
                        'deal_size': np.random.choice(['Small', 'Medium', 'Large', 'Enterprise'], 8000,
                                                      p=[0.4, 0.3, 0.2, 0.1])
                    })
                    # Add some missing values and outliers for realistic data
                    demo_data.loc[np.random.choice(demo_data.index, 200), 'profit_margin'] = np.nan
                    demo_data.loc[np.random.choice(demo_data.index, 50), 'sales_amount'] *= 10  # Outliers

                    st.session_state.dfs['enterprise_demo.csv'] = demo_data
                    st.session_state.selected_df = demo_data
                    st.session_state.data_loaded = True
                    st.success("Enterprise demo dataset loaded! (8,000 rows)")
                    st.rerun()

        if not uploaded_files and not st.session_state.data_loaded:
            # Enhanced welcome screen with enterprise features showcase
            st.info("Welcome to the Enterprise Data Analytics Platform")

            # Feature highlights in responsive columns
            col1, col2, col3 = st.columns(3, gap="large")

            with col1:
                st.markdown("""
                **AI-Powered Analytics**
                - Natural language queries
                - Auto-cleaning suggestions
                - Intelligent anomaly detection
                - Neural network modeling
                """)

            with col2:
                st.markdown("""
                **Enterprise Visualizations**
                - Interactive dashboards
                - Real-time sparklines
                - Responsive flex layouts
                - Accessibility-first design
                """)

            with col3:
                st.markdown("""
                **Performance Optimized**
                - Smart sampling (4GB RAM ready)
                - Advanced caching
                - Hardware-aware processing
                - Sub-20s model training
                """)

            return

        # --- Enhanced File Processing ---
        if uploaded_files:
            current_file_names = [f.name for f in uploaded_files]
            if st.session_state.last_uploaded_files != current_file_names:
                st.session_state.chart_configs = []
                st.session_state.filter_state = {}
                st.session_state.last_uploaded_files = current_file_names
                st.session_state.dfs = {}
                st.session_state.trained_models = {}

            # Process files with enhanced progress tracking
            with st.spinner("Processing files with enterprise optimization..."):
                progress_bar = st.progress(0)
                load_times = []
                quality_scores = []

                for i, uploaded_file in enumerate(uploaded_files):
                    start_time = time.time()

                    file_content = uploaded_file.read()
                    uploaded_file.seek(0)

                    df = load_data_enterprise(file_content, uploaded_file.name, file_type)
                    load_time = time.time() - start_time
                    load_times.append(load_time)

                    progress_bar.progress((i + 1) / len(uploaded_files))

                    if df is not None:
                        st.session_state.dfs[uploaded_file.name] = df
                        quality_score = df.attrs.get('quality_score', 0)
                        quality_scores.append(quality_score)

                        # Enhanced success message with quality metrics
                        speed_mb_s = (len(file_content) / 1024 / 1024) / load_time if load_time > 0 else 0
                        quality_icon = "Green" if quality_score > 80 else "Yellow" if quality_score > 60 else "Red"
                        st.success(f"{uploaded_file.name}: {df.shape[0]:,} × {df.shape[1]} | "
                                   f"Speed: {speed_mb_s:.1f} MB/s | "
                                   f"Quality: {quality_score:.0f}/100 {quality_icon}")
                    else:
                        st.error(f"Failed to load {uploaded_file.name}")

                # Enhanced overall performance metrics
                if load_times and quality_scores:
                    col1, col2, col3, col4 = st.columns(4, gap="medium")
                    with col1:
                        st.metric("Avg Load Time", f"{np.mean(load_times):.2f}s")
                    with col2:
                        total_rows = sum(len(df) for df in st.session_state.dfs.values())
                        st.metric("Total Rows", f"{total_rows:,}")
                    with col3:
                        st.metric("Avg Quality", f"{np.mean(quality_scores):.0f}/100")
                    with col4:
                        st.metric("Files Loaded", len(uploaded_files))

        if not st.session_state.dfs:
            st.error("No files were successfully loaded. Please check your file formats.")
            return

        # --- Dataset Selection with Enhanced Info ---
        selected_file = st.selectbox(
            "Select Dataset for Analysis",
            list(st.session_state.dfs.keys()),
            help="Choose which dataset to analyze with enterprise features"
        )
        df = st.session_state.dfs[selected_file]
        st.session_state.selected_df = df

        if df.empty:
            st.error("The selected dataset is empty.")
            return

        st.session_state.data_loaded = True
        df_hash = str(hash(str(df.shape) + str(df.columns.tolist())))

        # Quick dataset overview with flex container
        with st.container():
            col1, col2, col3, col4, col5 = st.columns(5, gap="medium")

            numeric_cols = df.select_dtypes(include=['number']).columns.tolist()
            categorical_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()
            datetime_cols = df.select_dtypes(include=['datetime']).columns.tolist()

            with col1:
                st.metric("Rows", f"{len(df):,}")
            with col2:
                st.metric("Columns", f"{len(df.columns)}")
            with col3:
                st.metric("Numeric", len(numeric_cols))
            with col4:
                st.metric("Categorical", len(categorical_cols))
            with col5:
                memory_mb = df.memory_usage(deep=True).sum() / 1024 ** 2
                quality_score = df.attrs.get('quality_score', 0)
                st.metric("Memory", f"{memory_mb:.1f} MB", delta=f"Q: {quality_score:.0f}/100")

        # --- Sidebar with Global Filters ---
        with st.sidebar:
            st.header("Global Controls")

            # Performance monitor
            if st.session_state.trained_models:
                st.success(f"{len(st.session_state.trained_models)} cached models")

            # Enhanced filtering
            st.subheader("Smart Data Filtering")
            with st.expander("Advanced Filters", expanded=False):
                # Categorical filters (optimized)
                if categorical_cols:
                    st.write("**Categorical Filters:**")
                    for col in categorical_cols[:4]:
                        try:
                            unique_vals = df[col].dropna().unique()
                            if len(unique_vals) > 100:
                                st.info(f"{col}: {len(unique_vals)} values (showing top 30)")
                                unique_vals = sorted(unique_vals)[:30]

                            selected = st.multiselect(
                                f"Filter {col}",
                                unique_vals,
                                key=f"filter_{col}",
                                max_selections=15
                            )
                            if selected:
                                st.session_state.filter_state[f"filter_{col}"] = selected
                        except Exception as e:
                            st.warning(f"Filter error for {col}: {e}")

                # Numeric filters (enhanced)
                if numeric_cols:
                    st.write("**Numeric Range Filters:**")
                    for col in numeric_cols[:6]:
                        try:
                            col_data = df[col].dropna()
                            if len(col_data) > 0:
                                min_val, max_val = float(col_data.min()), float(col_data.max())
                                if min_val != max_val:
                                    step = (max_val - min_val) / 1000
                                    range_val = st.slider(
                                        f"Range for {col}",
                                        min_val, max_val, (min_val, max_val),
                                        key=f"range_{col}",
                                        step=step,
                                        format="%.3f"
                                    )
                                    if range_val != (min_val, max_val):
                                        st.session_state.filter_state[f"filter_{col}"] = range_val
                        except Exception as e:
                            st.warning(f"Numeric filter error for {col}: {e}")

        # Apply filters globally
        if st.session_state.filter_state:
            filter_state_str = json.dumps(st.session_state.filter_state, default=str)
            df_filtered = apply_duckdb_filters(
                df_hash, filter_state_str, categorical_cols, numeric_cols, datetime_cols
            )

            if len(df_filtered) != len(df):
                reduction_pct = (1 - len(df_filtered) / len(df)) * 100
                st.info(f"Active Filters: {len(df_filtered):,} rows ({reduction_pct:.1f}% reduction)")
        else:
            df_filtered = df

        # --- Main Application Tabs ---
        tab1, tab2, tab3, tab4, tab5, tab6, tab7 = st.tabs(
            ["AI Assistant", "Analytics", "Data Preview", "Data Cleaning", "Anomaly Detection", "Visualizations", "ML Studio"]
        )

        with tab1:
            st.header("Conversational AI Assistant")
            st.markdown("*Ask questions about your data in natural language*")
            if query := st.chat_input("Ask about your data"):
                response = process_natural_query(query)
                st.write(response["message"])

        with tab2:
            st.header("Enterprise Data Analytics")
            try:
                eda_data = compute_eda_summary(df_hash, df.shape)
                st.subheader("Key Data Insights")
                insight_col1, insight_col2 = st.columns([2, 1], gap="large")
                with insight_col1:
                    for insight in eda_data.get('insights', ['No insights available'])[:3]:
                        st.info(f"{insight}")
                with insight_col2:
                    if len(numeric_cols) > 0:
                        st.write("**Numeric Trends**")
                        for col in numeric_cols[:3]:
                            try:
                                sample_data = df[col].dropna().sample(min(100, len(df[col].dropna())), random_state=42)
                                fig_mini = px.histogram(x=sample_data, nbins=20, height=100, title=col)
                                fig_mini.update_layout(showlegend=False, margin=dict(l=0, r=0, t=20, b=0), title={"font": {"size": 10}})
                                fig_mini.update_xaxes(showticklabels=False, showgrid=False)
                                fig_mini.update_yaxes(showticklabels=False, showgrid=False)
                                st.plotly_chart(fig_mini, use_container_width=True, key=f"spark_{col}")
                            except:
                                pass
                
                with st.expander("Dataset Explorer", expanded=False):
                    preview_col1, preview_col2 = st.columns([2, 1], gap="large")
                    with preview_col1:
                        st.markdown("**Dataset Overview**")
                        overview_data = {
                            "Metric": ["Total Rows", "Active Columns", "Memory Usage", "Data Quality Score", "Missing Data %", "Duplicate Rows"],
                            "Value": [f"{len(df):,}", f"{len(df.columns)}", f"{df.memory_usage(deep=True).sum() / 1024 ** 2:.1f} MB", f"{df.attrs.get('quality_score', 0):.0f}/100", f"{(df.isnull().sum().sum() / (len(df) * len(df.columns)) * 100):.1f}%", f"{df.duplicated().sum():,}"]
                        }
                        st.dataframe(pd.DataFrame(overview_data), hide_index=True, use_container_width=True)
                    with preview_col2:
                        st.markdown("**Column Analysis**")
                        type_analysis = {
                            "Type": ["Numeric", "Categorical", "DateTime", "Boolean", "Other"],
                            "Count": [len(numeric_cols), len(categorical_cols), len(datetime_cols), len(df.select_dtypes(include=['bool']).columns), len(df.columns) - len(numeric_cols) - len(categorical_cols) - len(datetime_cols) - len(df.select_dtypes(include=['bool']).columns)]
                        }
                        st.dataframe(pd.DataFrame(type_analysis), hide_index=True, use_container_width=True)
            except Exception as e:
                st.error(f"EDA analysis failed: {e}")

        with tab3:  # Data Preview Tab (Unchanged)
            st.header("Exploratory Data Preview")
            st.markdown("*Quick glance at your dataset with metadata and quality insights*")
            
            try:
                if st.session_state.data_loaded:
                    preview_data = generate_data_preview(df_hash)
                    
                    if 'error' in preview_data:
                        st.error(preview_data['error'])
                    else:
                        # Responsive layout for preview
                        preview_col1, preview_col2 = st.columns([3, 2], gap="medium")
                        
                        with preview_col1:
                            st.subheader("Data Sample")
                            st.markdown(f"Showing {preview_data['metadata']['sample_rows']} of {preview_data['metadata']['total_rows']:,} rows")
                            st.dataframe(
                                preview_data['preview_data'],
                                use_container_width=True,
                                height=300,
                                hide_index=False
                            )
                        
                        with preview_col2:
                            st.subheader("Dataset Metadata")
                            metadata_df = pd.DataFrame([
                                {
                                    'Column': col['name'],
                                    'Type': col['dtype'],
                                    'Missing %': f"{col['missing_percent']:.1f}%",
                                    'Unique': col['unique_count'],
                                    'Sample Values': ', '.join(map(str, col['sample_values'][:3]))
                                } for col in preview_data['metadata']['columns']
                            ])
                            st.dataframe(
                                metadata_df,
                                use_container_width=True,
                                column_config={
                                    'Missing %': st.column_config.ProgressColumn(
                                        'Missing %',
                                        min_value=0,
                                        max_value=100,
                                        format="%.1f%%"
                                    )
                                }
                            )
                        
                        # Additional insights in expander
                        with st.expander("Detailed Column Insights"):
                            for col in preview_data['metadata']['columns']:
                                st.markdown(f"**{col['name']} ({col['dtype']})**")
                                st.write(f"- Missing: {col['missing_count']:,} ({col['missing_percent']:.1f}%)")
                                st.write(f"- Unique Values: {col['unique_count']:,}")
                                if 'mean' in col and col['mean'] is not None:
                                    st.write(f"- Mean: {col['mean']:.2f}")
                                    st.write(f"- Std Dev: {col['std']:.2f}")
                                st.write("---")
                        
                        # Data quality indicator
                        quality_score = preview_data['quality_score']
                        quality_color = "Green" if quality_score > 80 else "Yellow" if quality_score > 60 else "Red"
                        st.metric("Data Quality Score", f"{quality_score:.0f}/100", delta=quality_color)
                        
            except Exception as e:
                st.error(f"Data preview error: {e}")
                logging.error(f"Data preview tab error: {e}")

        with tab4:  # Data Cleaning Tab
            st.header("Enterprise Data Cleaning")
            st.markdown("*Automated cleaning suggestions and manual overrides*")
            
            try:
                if st.session_state.data_loaded:
                    # Generate cleaning suggestions
                    cleaning_suggestions = suggest_cleaning_enterprise(df_hash)
                    
                    if not cleaning_suggestions:
                        st.info("No cleaning suggestions available for the current dataset.")
                    else:
                        st.subheader("Cleaning Suggestions")
                        suggestion_df = pd.DataFrame([
                            {
                                'Column': s['column'],
                                'Issue': s['description'],
                                'Severity': s['severity'].capitalize(),
                                'Action': s['type']
                            } for s in cleaning_suggestions
                        ])
                        st.dataframe(
                            suggestion_df,
                            use_container_width=True,
                            column_config={
                                'Severity': st.column_config.TextColumn(
                                    'Severity',
                                    help="High: Urgent action needed, Medium: Recommended, Low: Optional"
                                )
                            }
                        )
                        
                        # Allow applying suggestions
                        st.subheader("Apply Cleaning Actions")
                        selected_suggestion = st.selectbox(
                            "Select Suggestion to Apply",
                            options=[f"{s['column']} - {s['description']}" for s in cleaning_suggestions],
                            key="cleaning_suggestion_select"
                        )
                        if st.button("Apply Selected Cleaning", key="apply_cleaning_btn"):
                            suggestion_idx = [i for i, s in enumerate(cleaning_suggestions)
                                            if f"{s['column']} - {s['description']}" == selected_suggestion]
                            if suggestion_idx:
                                success = apply_cleaning_suggestion(cleaning_suggestions[suggestion_idx[0]])
                                if success:
                                    st.success(f"Applied cleaning to {cleaning_suggestions[suggestion_idx[0]]['column']}")
                                    st.session_state.dfs[selected_file] = st.session_state.selected_df
                                    st.rerun()
                                else:
                                    st.error("Failed to apply cleaning suggestion.")
                        
                        # Manual cleaning options
                        with st.expander("Manual Cleaning Options"):
                            cleaning_col1, cleaning_col2 = st.columns(2, gap="medium")
                            with cleaning_col1:
                                clean_col = st.selectbox("Select Column", df.columns, key="manual_clean_col")
                                clean_method = st.selectbox("Cleaning Method", CLEANING_METHODS, key="manual_clean_method")
                            with cleaning_col2:
                                if clean_method in ["mean", "median", "mode"]:
                                    fill_value = st.number_input("Custom Fill Value (optional)", value=0.0, key="manual_fill_value") if clean_method in ["mean", "median"] else st.text_input("Custom Fill Value (optional)", value="Unknown", key="manual_fill_text")
                            
                            if st.button("Apply Manual Cleaning", key="apply_manual_clean_btn"):
                                try:
                                    df_cleaned = df.copy()
                                    if clean_method == "drop":
                                        df_cleaned = df_cleaned.drop(columns=[clean_col])
                                    elif clean_method in ["mean", "median"]:
                                        fill_val = fill_value if clean_method == "mean" else df_cleaned[clean_col].median()
                                        df_cleaned[clean_col] = df_cleaned[clean_col].fillna(fill_val)
                                    elif clean_method == "mode":
                                        fill_val = fill_value if fill_value else df_cleaned[clean_col].mode().iloc[0] if len(df_cleaned[clean_col].mode()) > 0 else "Unknown"
                                        df_cleaned[clean_col] = df_cleaned[clean_col].fillna(fill_val)
                                    elif clean_method == "forward_fill":
                                        df_cleaned[clean_col] = df_cleaned[clean_col].ffill()
                                    elif clean_method == "backward_fill":
                                        df_cleaned[clean_col] = df_cleaned[clean_col].bfill()
                                    
                                    st.session_state.selected_df = df_cleaned
                                    st.session_state.dfs[selected_file] = df_cleaned
                                    st.success(f"Applied {clean_method} cleaning to {clean_col}")
                                    st.rerun()
                                except Exception as e:
                                    st.error(f"Manual cleaning failed: {e}")
                else:
                    st.info("Please load a dataset to perform data cleaning.")
            except Exception as e:
                st.error(f"Data cleaning error: {e}")
                logging.error(f"Data cleaning tab error: {e}")

        with tab5:  # Anomaly Detection Tab
            st.header("Enterprise Anomaly Detection")
            if not numeric_cols:
                st.warning("No numeric columns available for anomaly detection")
            else:
                config_col1, config_col2, config_col3 = st.columns(3, gap="medium")
                with config_col1:
                    anomaly_method = st.selectbox("Detection Method", ANOMALY_METHODS, key="anomaly_method")
                with config_col2:
                    if anomaly_method == "IsolationForest":
                        contamination = st.slider("Contamination Rate", 0.01, 0.3, 0.1, key="contamination")
                        params = {"contamination": contamination}
                    elif anomaly_method in ["Z-Score", "Modified Z-Score"]:
                        threshold = st.slider("Z-Score Threshold", 1.0, 5.0, 3.0, key="z_threshold")
                        params = {"threshold": threshold}
                    else:
                        multiplier = st.slider("IQR Multiplier", 0.5, 3.0, 1.5, key="iqr_multiplier")
                        params = {"multiplier": multiplier}
                with config_col3:
                    selected_features = st.multiselect("Features for Detection", numeric_cols, default=numeric_cols[:3], key="anomaly_features")
                
                if st.button("Detect Anomalies", key="detect_anomalies_btn") and selected_features:
                    with st.spinner(f"Running {anomaly_method} anomaly detection..."):
                        anomaly_result = detect_anomalies_enterprise(df_hash, anomaly_method, params)
                        st.session_state.anomaly_results = anomaly_result
                
                if st.session_state.anomaly_results and "error" not in st.session_state.anomaly_results:
                    result = st.session_state.anomaly_results
                    summary_col1, summary_col2, summary_col3, summary_col4 = st.columns(4, gap="medium")
                    with summary_col1:
                        st.metric("Method", result["method"])
                    with summary_col2:
                        st.metric("Anomalies Found", f"{result['outlier_count']:,}")
                    with summary_col3:
                        anomaly_rate = result['outlier_count'] / len(result['outliers']) * 100
                        st.metric("Anomaly Rate", f"{anomaly_rate:.1f}%")
                    with summary_col4:
                        st.metric("Features Used", len(result['columns']))
                    
                    if len(result['columns']) >= 2:
                        viz_df = st.session_state.selected_df.loc[result['index']].copy()
                        viz_df['is_anomaly'] = result['outliers'] == -1
                        viz_df['anomaly_score'] = result['anomaly_scores']
                        fig_anomaly = px.scatter(viz_df, x=result['columns'][0], y=result['columns'][1], color='is_anomaly', size='anomaly_score', title=f"Anomaly Detection Results - {result['method']}", color_discrete_map={True: 'red', False: 'blue'}, labels={'is_anomaly': 'Anomaly'})
                        st.plotly_chart(fig_anomaly, use_container_width=True)

        with tab6:  # Visualizations Tab
            st.header("Enterprise Visualization Studio")
            # This tab is now just for chart building, filters are in the main sidebar
            st.sidebar.subheader("Visualization Config")
            suggested_charts = suggest_chart_type(df.shape, len(numeric_cols), len(categorical_cols))
            if suggested_charts:
                st.sidebar.info(f"AI Suggestions: {', '.join(suggested_charts[:3])}")
            
            chart_col1, chart_col2 = st.sidebar.columns(2)
            if chart_col1.button("Add Chart", key="add_viz_chart_btn"):
                st.session_state.chart_configs.append({"chart_type": suggested_charts[0] if suggested_charts else CHART_OPTIONS[0], "id": len(st.session_state.chart_configs)})
                st.rerun()
            if st.session_state.chart_configs and chart_col2.button("Clear All", key="clear_viz_charts_btn"):
                st.session_state.chart_configs = []
                st.rerun()

            if st.session_state.chart_configs:
                chart_tabs = st.tabs([f"Chart {i + 1}" for i in range(len(st.session_state.chart_configs))])
                figs = []
                for idx, chart_tab in enumerate(chart_tabs):
                    with chart_tab:
                        if idx < len(st.session_state.chart_configs):
                            config = st.session_state.chart_configs[idx]

                            # --- Chart Configuration UI ---
                            config_col1, config_col2, config_col3, config_col4 = st.columns(4, gap="medium")

                            with config_col1:
                                chart_type = st.selectbox(
                                    "Chart Type",
                                    CHART_OPTIONS,
                                    index=CHART_OPTIONS.index(config["chart_type"]) if config["chart_type"] in CHART_OPTIONS else 0,
                                    key=f"chart_type_viz_{idx}"
                                )
                                st.session_state.chart_configs[idx]["chart_type"] = chart_type

                            with config_col2:
                                # Smartly suggest appropriate columns for axes based on chart type
                                if chart_type in ["Scatter Plot", "Line Chart"]:
                                    x_options = numeric_cols + datetime_cols
                                    y_options = numeric_cols
                                elif chart_type == "Bar Chart":
                                    x_options = categorical_cols
                                    y_options = numeric_cols
                                elif chart_type == "Histogram":
                                    x_options = numeric_cols
                                    y_options = []
                                elif chart_type in ["Box Plot", "Violin Plot"]:
                                    x_options = categorical_cols + [None]
                                    y_options = numeric_cols
                                elif chart_type == "Pie Chart":
                                    x_options = categorical_cols
                                    y_options = numeric_cols
                                elif chart_type == "Anomaly Plot":
                                    x_options = numeric_cols
                                    y_options = numeric_cols
                                else:
                                    x_options = list(df_filtered.columns)
                                    y_options = numeric_cols

                                x_axis = st.selectbox("X-axis", x_options if x_options else ["No suitable columns"], key=f"x_axis_viz_{idx}") if x_options else None

                            with config_col3:
                                y_axis = st.selectbox("Y-axis", y_options if y_options else ["No suitable columns"], key=f"y_axis_viz_{idx}") if y_options else None

                            with config_col4:
                                color_col = st.selectbox("Color By", [None] + categorical_cols, key=f"color_viz_{idx}") if categorical_cols else None

                            # --- Advanced Chart Options Expander ---
                            with st.expander("Advanced Chart Options"):
                                adv_col1, adv_col2, adv_col3 = st.columns(3)
                                with adv_col1:
                                    theme = st.selectbox("Theme", THEME_OPTIONS, key=f"theme_viz_{idx}")
                                    custom_title = st.text_input("Title", f"{chart_type} - {selected_file}", key=f"title_viz_{idx}")
                                with adv_col2:
                                    height = st.slider("Height (px)", 300, 1000, 600, key=f"height_viz_{idx}")
                                    width = st.slider("Width (%)", 50, 100, 100, key=f"width_viz_{idx}")
                                with adv_col3:
                                    show_legend = st.checkbox("Show Legend", True, key=f"legend_viz_{idx}")
                                    show_grid = st.checkbox("Show Grid", True, key=f"grid_viz_{idx}")
                                    enable_zoom = st.checkbox("Enable Zoom", True, key=f"zoom_viz_{idx}")

                            # --- Chart Generation Logic ---
                            fig = None
                            if chart_type == "Correlation Heatmap":
                                if len(numeric_cols) >= 2:
                                    try:
                                        plot_df = df_filtered.sample(n=min(10000, len(df_filtered)), random_state=42)
                                        corr_matrix = plot_df[numeric_cols].corr()
                                        fig = px.imshow(corr_matrix, text_auto=True, aspect="auto", color_continuous_scale="RdBu", title=custom_title, height=height)
                                    except Exception as e:
                                        st.error(f"Correlation heatmap failed: {e}")
                                else:
                                    st.warning("Need at least 2 numeric columns for a heatmap.")
                            
                            elif chart_type == "Map View":
                                lat_col, lon_col = find_lat_lon_columns(df_filtered.columns)
                                if lat_col and lon_col:
                                    map_data = df_filtered[[lat_col, lon_col]].dropna()
                                    st.map(map_data, use_container_width=True)
                                else:
                                    st.warning("Map requires latitude/longitude columns (e.g., 'lat', 'lon').")

                            else:
                                if x_axis or (y_axis and chart_type not in ["Histogram"]):
                                    try:
                                        plot_df = df_filtered.sample(n=min(15000, len(df_filtered)), random_state=42)
                                        plot_args = {'data_frame': plot_df, 'title': custom_title, 'template': theme, 'height': height}
                                        if color_col:
                                            plot_args['color'] = color_col

                                        if chart_type == "Scatter Plot":
                                            fig = px.scatter(x=x_axis, y=y_axis, **plot_args)
                                        elif chart_type == "Line Chart":
                                            fig = px.line(x=x_axis, y=y_axis, **plot_args)
                                        elif chart_type == "Bar Chart":
                                            fig = px.bar(x=x_axis, y=y_axis, **plot_args)
                                        elif chart_type == "Histogram":
                                            fig = px.histogram(x=x_axis, **plot_args)
                                        elif chart_type == "Box Plot":
                                            fig = px.box(x=x_axis, y=y_axis, **plot_args)
                                        elif chart_type == "Violin Plot":
                                            fig = px.violin(x=x_axis, y=y_axis, **plot_args)
                                        elif chart_type == "Pie Chart":
                                            fig = px.pie(names=x_axis, values=y_axis, **plot_args)
                                    
                                    except Exception as e:
                                        st.error(f"Chart creation failed: {e}")
                                else:
                                    st.info("Please select appropriate axes for the chart.")

                            # --- Display Chart and Add to Export List ---
                            if fig:
                                fig.update_layout(showlegend=show_legend, xaxis_showgrid=show_grid, yaxis_showgrid=show_grid)
                                st.plotly_chart(fig, use_container_width=True, key=f"plotly_viz_{idx}")
                                figs.append(fig)

        with tab7:  # ML Studio Tab
            st.header("Enterprise Machine Learning Studio")
            ml_col1, ml_col2 = st.columns([1, 1], gap="large")
            with ml_col1:
                with st.expander("Advanced K-Means Clustering", expanded=True):
                    if not numeric_cols:
                        st.warning("No numeric columns for clustering")
                    else:
                        auto_k = st.checkbox("Auto-suggest k", key="auto_k_check_ml")
                        selected_features = st.multiselect("Features for Clustering", numeric_cols, default=numeric_cols[:4], key="kmeans_features_ml")
                        if auto_k and selected_features:
                            k = optimal_k_cached(df_hash, selected_features)
                            st.success(f"AI Suggested k: {k}")
                        else:
                            k = st.slider("Number of clusters", 2, 10, 3, key="k_slider_ml")
                        
                        if st.button("Run Clustering", key="run_clustering_ml_btn") and selected_features:
                            with st.spinner("Running K-Means..."):
                                cluster_result = perform_kmeans_optimized(df_filtered, selected_features, k)
                                if "error" in cluster_result:
                                    st.error(f"{cluster_result['error']}")
                                else:
                                    st.success(f"Clustering completed!")
                                    if len(selected_features) >= 2:
                                        cluster_data = df_filtered[selected_features].iloc[cluster_result['index']]
                                        cluster_data['cluster'] = cluster_result['labels']
                                        fig_cluster = px.scatter(cluster_data, x=selected_features[0], y=selected_features[1], color='cluster')
                                        st.plotly_chart(fig_cluster, use_container_width=True)
                                    st.write("Cluster sizes:")
                                    st.dataframe(pd.Series(cluster_result['labels']).value_counts())
            
            with ml_col2:
                with st.expander("Advanced ML Models & AutoML", expanded=True):
                    if not (numeric_cols or categorical_cols):
                        st.warning("No suitable features for modeling")
                    else:
                        model_config_col1, model_config_col2 = st.columns(2, gap="medium")
                        with model_config_col1:
                            model_choice = st.selectbox("Model Type", ML_MODELS + ["AutoML Comparison"], key="ml_model_choice")
                            task_type = st.selectbox("Task", ["regression", "classification"], key="ml_task_type")
                        with model_config_col2:
                            enable_tuning = st.checkbox("Hyperparameter tuning", key="ml_enable_tuning")
                            enable_preprocessing = st.checkbox("Auto preprocessing", value=True, key="ml_enable_preprocessing")
                        
                        available_features = numeric_cols + categorical_cols
                        x_features = st.multiselect("Features (X)", available_features, default=numeric_cols[:4] if len(numeric_cols) >= 4 else numeric_cols, key="ml_x_features", help="Select features for model training")
                        target_options = [col for col in df_filtered.columns if col not in x_features]
                        y_target = st.selectbox("Target (Y)", target_options, key="ml_y_target")

                        if model_choice == "MLP":
                            hidden_layer_1 = st.slider("Layer 1 Neurons", 10, 200, 50, key="mlp_layer1")
                            hidden_layer_2 = st.slider("Layer 2 Neurons", 10, 200, 50, key="mlp_layer2")
                            max_iterations = st.slider("Max Iterations", 100, 1000, 200, key="mlp_max_iter")
                            hidden_layers = (hidden_layer_1, hidden_layer_2)

                        if st.button("Train Advanced Model", key="train_advanced_model_btn") and x_features and y_target:
                            with st.spinner(f"Training {model_choice} model..."):
                                if model_choice == "MLP":
                                    ml_result = train_mlp_model(df_filtered, x_features, y_target, task_type, hidden_layers=hidden_layers, max_iter=max_iterations)
                                elif model_choice == "AutoML Comparison":
                                    ml_result = generate_ml_model_comparison(df_filtered, x_features, y_target, task_type)
                                elif model_choice == "RandomForest":
                                    ml_result = perform_random_forest_optimized(df_filtered, x_features, y_target, task_type, preprocess=enable_preprocessing, tune=enable_tuning)
                                else:
                                    ml_result = {"error": "Unsupported model"}
                                
                                if "error" in ml_result:
                                    st.error(f"{ml_result['error']}")
                                else:
                                    st.success(f"{model_choice} model trained successfully!")
                                    if model_choice == "AutoML Comparison":
                                        comparison_df = pd.DataFrame({
                                            'Model': list(ml_result.keys())[:-1],
                                            'Key Metric': [ml_result[m]['metrics'].get('r2' if task_type == 'regression' else 'f1', 0) for m in list(ml_result.keys())[:-1]],
                                            'Training Time': [ml_result[m]['training_time'] for m in list(ml_result.keys())[:-1]]
                                        })
                                        st.dataframe(comparison_df)
                                    else:
                                        metrics_df = pd.DataFrame(ml_result['metrics'].items(), columns=['Metric', 'Value'])
                                        st.dataframe(metrics_df)

    except Exception as e:
        st.error(f"Enterprise application error: {e}")
        logging.error(f"Enterprise main application error: {e}")
        st.markdown("### Error Recovery")
        recovery_col1, recovery_col2, recovery_col3 = st.columns(3)
        with recovery_col1:
            if st.button("Soft Reload", key="soft_reload_btn"):
                st.rerun()
        with recovery_col2:
            if st.button("Clear All Cache", key="clear_all_cache_btn"):
                st.cache_data.clear()
                st.cache_resource.clear()
                st.success("All caches cleared!")
        with recovery_col3:
            if st.button("Emergency Reset", key="emergency_reset_btn"):
                for key in list(st.session_state.keys()):
                    del st.session_state[key]
                st.rerun()


# --- Run the Application ---
if __name__ == "__main__":
    main_enterprise()
